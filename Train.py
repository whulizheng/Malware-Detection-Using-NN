import Preprocessor
import Utils
import Classifier_FCN
from sklearn import preprocessing
import numpy as np

if __name__ == "__main__":
    config = Utils.readjson("config.json")
    Transformer = Preprocessor.Transformer(
        config["advanced"]["img_width"], config["advanced"]["img_height"])
    Classifier = Classifier_FCN.Classifier_FCN(
        config["advanced"]["input_shape"],
        config["model"]["nb_classes"],
        config["model"]["model_path"]
    )
    enc = preprocessing.OneHotEncoder()
    enc.fit(np.array(range(config["model"]["nb_classes"])).reshape(-1, 1))
    train_size = config["data"]["train_size"]
    count = 0

    mal_datasets = Utils.scan_file(config["data"]["mal_train_dataset_dir"])[0]
    mal_train_datasets = []
    for dataset in mal_datasets:

        flag = 0
        for types in config["data"]["support_type"]:
            if dataset.find(types) >= 0:
                count = count + 1
                flag = 1
                break
        if flag:
            mal_train_datasets.append(dataset)
            if count > train_size/2:
                break

    count = 0
    nor_datasets = Utils.scan_file(config["data"]["nor_train_dataset_dir"])[0]

    nor_train_datasets = []
    for dataset in nor_datasets:
        flag = 0
        for types in config["data"]["support_type"]:
            if dataset.find(types) >= 0:
                flag = 1
                count = count + 1
                break
        if flag:
            nor_train_datasets.append(dataset)
            if count > train_size/2:
                break

    y_train = []
    x_train = []
    print(len(nor_train_datasets))
    print(len(mal_train_datasets))
    for i in nor_train_datasets:
        y_train.append(0)
        matrix = Transformer.Load_file(
            config["data"]["nor_train_dataset_dir"]+i)
        img = Transformer.transform(matrix)
        img = np.array(img).reshape(
            (config["advanced"]["img_width"], config["advanced"]["img_height"], 1))
        x_train.append(img)
        print(i+"\t0")
    print("读取普通文件结束")
    for i in mal_train_datasets:
        y_train.append(1)
        matrix = Transformer.Load_file(
            config["data"]["mal_train_dataset_dir"]+i)
        img = Transformer.transform(matrix)
        img = np.array(img).reshape(
            (config["advanced"]["img_width"], config["advanced"]["img_height"], 1))
        x_train.append(img)
        print(i+"\t1")
    print("读取恶意文件结束")
    y_train = enc.transform(np.array(y_train).reshape(-1, 1)).toarray()
    x_train = np.array(x_train)

    Classifier.fit(x_train, y_train,
                   config["model"]["batch_size"], config["model"]["epoch"])

    print("训练结束")
